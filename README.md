# SORTER
### Sorter of Orthologous Regions for Target Enrichment Reads

Jonas Mendez-Reneau1, Erin Sigel2, Gordon Burleigh3
1. University of Louisiana Lafayette
2. University of New Hampshire, Durham
3. University of Florida, Gainesville

CURRENT VERSION IS A PRE-RELEASE AWAITING PUBLICATION

SORTER is a flexible user-customizable set of python scripts for building a variety of locus-alignment matrices from target-enrichment datasets. The three overarching goals of the pipeline are to:

1. Build multiple sequence alignments of orthologous sequences for hundreds or thousands of loci generated from target-enrichment datasets. SORTER allows the exploration of orthology among sequences associated with targeted reference loci using within and among sample identity clustering (USEARCH). Given appropriate clustering identity, this can filter and separate paralogs derived from the same locus into separate orthologous sets across all samples, effectively generating additional loci for analysis when paralogs are present. 

2. Phase bi-allelic variation from previously determined orthologs to build alignments from putative allelic haplotypes where each sample is represented by two sequences representing heterozygous or homozygous alleles.

3. Infer hybrid haplotypes based on similarity to potential progenitor samples. This generates a multiple sequence alignment where hybrid samples can have two or more tips, depending on the number of hybrid haplotypes present in the sample. This was originally designed and probably works best for allopolyploid hybrids where we expect lower levels of inter-homeologous recombination, but we have had some success in detecting hybrid haplotypes from putative homoploid hybrids.

Contact:jonasmrgrad@gmail.com



### Dependencies:

Biopython (Python 2.7.x)
Perl
Trim Galore v 0.6.4 (with cutadapt v1.1B)
bwa v 0.7.17-r1188
SAMTools v 1.9 (using htslib 1.9)
BCFTools v1.9 (using htslib 1.9)
MAFFT v 7.450
SPAdes v 3.11.1
Seqtk v 1.3-r107-dirty
Vcfutils.pl (from bcftools v 1.9)
Trimal v 1.2rev59
Usearch v 11.0.667_i86linux32


### Scripts:
Stage1A.py
Stage1B.py
Stage2.py
Stage3.py
annotatedupes
deinterleave.py
getlongestcontig.py
keeplongest.py
seqclean.py


## General Definition of Stages and Output:

#### Stage1A.py

The first script trims raw reads (trimgalore) and builds contigs (SPADES) for each sample, making folders for each sample and related files to be used downstream.

### Stage1B.py

Stage1B.py takes contigs generated by spades, first generating "consensus alleles" by collapsing highly similar contigs mapping to the same reference within a sample into consensus sequences. An identity threshold of 98-99% identity (-c1 flag) is recommended for generating consensus alleles. Consensus alleles among all samples are compiled according to reference locus for a second round of clustering (-c2 flag) to filter potentially paralogous locus sets. Sensitivity analyses of a range of identities [i.e. 70-90%] is recommended to assess the relative effect of consensus allele copy number per locus-cluster, but Edgar (2005) recommends atleast 75% identity thresholds for retrieving orthologs.

Stage1B.py outputs aligned fasta files of consensus alleles for clustered loci in the "diploids" folder with files ending in "trimmed", we leave multi-copy sequences in the alignment, leaving the choice up to the user as to how to filter samples with multiple sequences per locus (e.g. choose the longest sequence). A csv summary table for all retrieved consensus-alleles per sample per locus prior to among sample clustering can be found in the "diploids" folder, along with consensus allele files corresponding to references and samples. A secondary summary csv file found in the "diploidclusters" shows consensus-allele distributions across samples and loci after clustering. 

### Stage2.py
This script will take the putatively orthologous clustered loci generated from Stage1B.py and remaps reads to them in order to phase sequences (samtools phase) to generate putative haplotypes. This phased dataset can be used to identify potential hybrid/allopolyploid species. Phased sequences for each sample should be sister to each other with relatively strong support in a phylogeny, or multiple samples of the same species should at the very least be monophyletic. 
If you observe phased samples that don't result as sister to themselves, or are associated with poor node support values they likely indicate a hybrid individual. You may want to filter potential hybrids if you want to use Stage3.py to infer hybrid haplotypes, as the inference is highly dependent on correct identification of potential progenitors. (i.e. accidentally including a hybrid as a progenitor could reduce the ability for the pipeline to accurately identify differing hybrid haplotypes)

### Stage3.py
This script will phase and assign orthology to sequences in samples suspected to be allopolyploid or hybrid in origin, outputing multiple-sequence alignments with hybrids represented by two or more tips, depending on how many progenitors species contributed to the hybrid. It uses the putatively orthologous and phased datasets generated from Stage1B.py and Stage2.py as progenitor references to assign identities to different genomes or haplotypes found in a hybrid. Thus, this script assumes that the samples included through Stage1B.py and Stage2.py will serve as possible progenitor contributors to each hybrid sample. Due to this inference can be highly impacted by having miss-identified samples or cryptid hybrids included in the analysis. The script outputs alignment files, where hybrid sequences are annotated with the name of putative progenitors, allowing for analyses linking hybrid haplotypes across loci without a priori knowlegde of linkage or genomes. Disparate sequence sets may represent the same haplotype that was inferred to another species due to ILS or gene level heterogeneity, so we recommend preliminary phylogenetic analyses to assess if disparate haplotypes should be further combined (i.e. the two sets result in a shared and well supported clade)


## Running the pipeline:

### Stage1A.py
1. Place all paired raw reads for all samples in the same folder.
2. Paired reads for each sample need to follow this naming scheme for the pipeline to work:

	@@##_taxon_R1.fastq and @@##_taxon_R2.fastq
	
	@@## can be any set of numbers and or letters used as unique identifiers for each sample, do not use underscores or other symbols other than numbers or letters
3. Trimmed reads and contigs for each sample will be placed in their own folder within the "cleanfastq" folder that is made. This will serve as the working directory for the rest of the scripts.

Flags:

-wd : This will be the path to the folder where you have stored the labeled paired-end reads. make sure you include '/' at the end of the path.

command line example:

python Stage1A.py -wd /path/to/paired/reads/

### Stage1B.py
BEFORE RUNNING MAKE SURE YOU HAVE DONE THE FOLLOWING:

Before running any more scripts, prepare the working directory (i.e. "cleanfastq" folder generated in Stage1A.py) with required files and folders.

3. MAKE THE FOLLOWING FOLDERS:

	workingdirectory/cleanfastq/diploids (this folder outputs Phase1 alignments)
	
	workingdirectory/cleanfastq/diploidclusters (un-aligned clustered loci are stored here)
	
	workingdirectory/cleanfastq/diploids_phased (if phasing with Phase2.py, this folder outputs Phase2 Phased alignments for diploids.)
	
	workingdirectory/phaseset (if using Phase3.py, this folder will contain hybrid/allopolyploid sample files and alignments)
	

4. PLACE ALL EXTERNAL PYTHON SCRIPTS IN WORKING DIRECTORY:

	workingdirectory/getlongestcontig.py
	
	workingdirectory/deinterleave.py
	
	workingdirectory/seqclean.py
	
	workingdirectory/annotatedupes
	
	workingdirectory/keeplongest.py
	

5. Know the working directory of your probe references for command line input, may be placed in /workingdirectory/cleanfastq/

6. Locus references should be in FASTA format. Reference IDS may have any labels, but each unique reference must be annotated with "L#_..." at the begnning of the sequence ID (i.e. directly after the ">") to generate an index for all references to be used by the pipeline.

AS FOLLOWS:
		
	>L1_*
	>L2_*
	>L3_*
	...
	>L20_*
	>L21_*
	...
	>L200_*
	etc... 
		
(*'s representing any other ID format present in your reference; The pipeline ignores this information and is just interested in identifying the index number from references)

7. Before running any script make sure to load all required software and python version


FLAGS:

-wd WORKING DIRECTORY : -wd /workingdirectory/cleanfastq/ (DIRECTORY PATH STRING MUST START AND END IN '/')

-ref PROBE REFERENCE DIRECTORY (FASTA FILE): -ref /path/to/ref.fasta


-loci NUMBER OF REFERENCE LOCI (e.g. -loci 550)

-c1 1st CLUSTER ID (WITHIN SAMPLE FOR CONSENSUS ALLELES, .97-.99 Recommended) 

-c2 2nd CLUSTER ID (AMONG SAMPLES FOR LOCUS-CLUSTERS, .70 - .90 recommended, may depend on taxonomic breadth of ingroup/outgroups.


-reclust (T/F) IF T, ONLY RERUNs LOCUS CLUSTERING + ALIGNMENT, WILL NOT REBUILD CONSENSUS ALLELES (i.e. keeps -cs, -csn, and -csl output from previous run). 

CLEARS PREVIOUS CLUSTERED LOCI, BACK UP OUTPUT IF NEEDED TO COMPARE CLUSTERING THRESHOLDS.

	RUNNING -reclust T IGNORES -c1 -cs -csl -csn VALUES, USING VALUES FROM PREVIOUS RUN; TO CHANGE THESE FLAGS YOU MUST RERUN Phase1.py WITH -reclust F

-cs TAKE SPADES CONTIGS or SCAFFOLDS? (input as: scaffold or contig)

-csn TAKE N CONTIGS/SCAFFOLDS PER LOCUS PER SAMPLE FOR CONSENSUS ALLELES/ORTHOLOG CLUSTERING

-csl ONLY TAKE CONTIGS/SCAFFOLDS LARGER THAN N LENGTH

-al number of iterations for MAFFT alignments, --maxiter option (e.g. -al 1000)

-indel indels have to be present in atleast XX% of sequences to be kept; trimal -gt option

-idformat (full/copies/onlysample/*) OUTPUTS FINAL ALIGNMENT SEQUENCE IDS IN FOLLOWING FORMATS:

	-idformat full = >L100_cl0_@@##_sampleid_0 ; Keeps full annotation. If last annotation > 0, it signifies samples with multiple consensus alleles per locus-cluster; potential heterozygotes, discontinouos haplotype fragments or unclustered paralogs, may consider higher-c2 (among samples) or -c1 (within samples) clustering values.
	
	-idformat copies = >@@##_sampleid_0 ; Keeps sample id and consensus allele copy count per cluster. i.e. if last annotation >0 signifies samples with multiple consensus alleles per locus-cluster; see above
	
	-idformat onlysample = >@@##_sampleid ; Keeps only the sample id across locus-cluster alignments, easiest for concatenation across all locus-cluster alignments
	-format * if you mispell the above arguments or leave -id format blank, it will keep the default trimal headers; e.g. >L100_cl0_WA10_sampleid_0 1230 bp


COMMAND LINE EXAMPLE:

python Stage1B.py -wd /workingdirectory/cleanfastq/ -ref /workingdirectory/cleanfastq/references.fasta -loci 450 -reclust F -c1 .99 -c2 .80 -cs contig -csn 10 -csl 300 -al 1000 -indel 0.25 -idformat onlysample


### Stage2.py

Stage2.py takes the dataset generated in Stage1B.py, maps reads to consensus alleles in order to phase haplotypes using samtools phase. The phased clustered loci are then re-aligned for analysis.

*** MAKE SURE YOU HAVE MADE THE /workingdirectory/diploids_phased/ DIRECTORY BEFORE RUNNING.

FLAGS:

-wd WORKING DIRECTORY : -wd /workingdirectory/cleanfastq/ (DIRECTORY PATH STRING MUST START AND END IN '/') should be the same directory used in Stage1B.py

-pq PHASE QUALITY; samtools phase -q flag (atleast 20 recommended)

-al number of iterations for MAFFT alignments, --maxiter option (e.g. -al 1000)

-indel indels have to be present in atleast XX% of sequences to be kept

-idformat (full/copies/onlysample/*) OUTPUTS FINAL FASTA ALIGNMENT SEQUENCE IDS IN FOLLOWING FORMATS:

	-idformat full = >L100_cl0_@@##_sampleid_ph0/ph1_0 ; Keeps full anottation.  If last annotation > 1, it signifies samples with multiple consensus alleles per locus-cluster that were phased.
	
	-idformat phase = >@@##_sampleid_ph0/ph1 ; RECOMMENDED FOR PHASING. Keeps sample id and phase annotations.
	
	-idformat onlysample = >@@##_sampleid ; Keeps only the sample for sequence headers, removing phase annotation. You will have to decide how to manage phased or other sequence copies with identical id names.
	
	-idformat * :if you mispell the above arguments or leave -id format blank, it will keep the default trimal headers; e.g. >L100_cl0_@@##_sampleid_0 1230 bp

-cdbonly (T/F) set to 'T' to only make blast database for phasing and blasting allopolyploid/hyrbid samples in Phase3.py. 
	Use this setting if you wish to skip phasing your diploid locus-cluster samples but still want to process polyploids/hyrbids with Phase3.py

COMMAND LINE EXAMPLE

python Phase2.py -wd /working/directory/ -pq 20 -al 1000 -indel .25 -idformat phase -cdbonly F


### Phase3.py


BEFORE RUNNING MAKE SURE YOU HAVE DONE THE FOLLOWING:

1. MAKE A FOLDER TO SERVE AS THE WORKING DIRECTORY FOR THE SET OF ALLOPOLYPLOIDS OR HYBRIDS TO BE PHASED AS /workingdirectory/phaseset/

2. ADD RAW PAIR-END FASTQ READS FOR EACH SAMPLE IN PHASESET WORKING DIRECTORY, FOLLOWING THIS NAMING SCHEME FOR PAIRED END READS, RESPECTIVELY(SAME AS Phase1.py):

	@@##_species1id_R1.fastq and @@##_species1id_R2.fastq
	
	Make sure paired end reads are signified with R1/R2 as shown above
	
	@@ values can be any set of two alphabetic letters and ## can be any unique set of two intergers per sample, MUST BE IDENTICAL FOR THE SAME SAMPLE
	
	These Unique Identifiers are used to differentiate multiple samples of with the same species id (i.e. if multiple samples have the same 'species1id')
	
4. PLACE ALL EXTERNAL PYTHON SCRIPTS IN WORKING DIRECTORY (Same as Phase1.py):

	workingdirectory/getlongestcontig.py
	
	workingdirectory/deinterleave.py
	
	workingdirectory/seqclean.py
	
	workingdirectory/annotatedupes
	
	workingdirectory/keeplongest.py
	
5. Know the working directory of your probe references for command line input, may be placed in /workingdirectory/

6. Before running script make sure to load all required software and python version 

FLAGS

-wd WORKING DIRECTORY 

-ref PROBE REFERENCE DIRECTORY (FASTA FILE) SAME AS Phase1.py

-loci NUMBER OF REFERENCE LOCI SAME AS Phase1.py

-c1 1st CLUSTER ID (WITHIN SAMPLE FOR CONSENSUS ALLELES, .99 Recommended) 

-trimgalore RUN TRIMGALORE TO TRIM RAW READS? (T/F)***

-spades RUN SPADES ASSEMBLY? (T/F)***

-onlyprocess (T/F) ONLY RUN TRIMGALORE AND SPADES FOR CONTIG PROCESSING?; RUN AGAIN WITH -trimgalore and -spades as F FOR PIPELINE (set as F if running processing + pipeline in one run)

-cs TAKE SPADES CONTIGS or SCAFFOLDS? (MUST INPUT AS: scaffold or contig)

-csn TAKE N CONTIGS/SCAFFOLDS PER LOCUS PER SAMPLE FOR CONSENSUS ALLELES. DEPENDING ON SUSPECTED PLOIDY, MULTIPLY BY 2 TO ACCOUNT FOR HETEROZYGOUS VARIANTS (i.e. tetraploid 4*2=8, triploid 3*2=6. 8-10 for unknown samples is recommended)

-csl ONLY TAKE CONTIGS/SCAFFOLDS LARGER THAN N LENGTH

-pq PHASE QUALITY; SAMTOOLS -Q FLAG; MINIMUM READS TO CALL A PHASE (atleast 20 recommended)

-n PERCENT OF MISSING DATA (N) ALLOWED IN PHASED SEQUENCES? (atleast 50% bp representation recommended, input as -n 50 , NOT AS DECIMAL)

-al number of iterations for MAFFT alignments (1000 recommended)

-indel indels have to be present in atleast XX% of sequences to be kept; 0.25 recommended for ~50 samples (INPUT AS DECIMAL)


Output Files:

/workingdir/phaseset/sample/diploidclusters/*_phase.fasta extension making polyploid/hybrid sample ids in the following format :

>@@##_sampleid_phase(0/1)

/workingdir/phaseset/sample/diploidclusters/*_diploidhit.fasta extension making polyploid/hybrid sample ids in the following format :

>@@##_sampleid_diploidhit

the *_trimmed.fasta files are annotated as @@##_sampleid_diploidhit_phase(0/1)

COMMAND LINE EXAMPLE:

python Phase3.py -wd /workingdirectory/ -ref /workingdirectory/references.fasta -loci 450 -spades T -trimgalore T -op F -c1 .90 -cs contig -csn 8 -csl 350 -pq 20 -n 50 -al 1000 -indel 0.25
